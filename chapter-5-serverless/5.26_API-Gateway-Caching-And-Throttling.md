### API Gateway Caching & Throttling

1. Caches endpoint responses - reducing the number of calls made to an endpoint improving the latency for requests to an API.
2. TTL - When caching is enabled, API Gateway caches responses from your endpoint for a specified TTL period, in seconds. The defualt is 300 seconds.
3. API Gateway returns cached responses - API Gateway then responds to new requests by looking up the response from the cache, instead of making a new request to your application.

Users > Make request to API Gateway > API Gateway sends request to Lambda Function > Lambda sends response to API Gateway and is cached for 300s. Then someone comes along and makes a similar request, API Gateway sends that cached response reducing latency to that later request.

API Gateway actually reduces the number of API calls made this way because it's not making calls but rather serving the cached responses, reducing the need for throttling.

#### Throttling

The purpose of API Gateway Throttling is to prevent API from being overwhelmed by too many requests.

1. Default Limits - By default, API Gateway limits the steady-state request rate to 10,000 requests per second, per region.
2. Concurrent Requests - The maximum concurrent requests is 5,000 requests across all APIs, per Region. You can request an increase on these limits.
3. 429 Error - If you exceed 10,000 requests per second, or 5,000 concurrent requests, you will recieve a `429 Too Many Requests` error message.

##### For Example

> An application recieves 10,000 requests per second - the requests are spread evenly across each one second period. 10 requests per millisecond. API Gateway processes all of the requests without dropping any.

> An application recieves 10,000 requests in first milliseconds - the per concurrent requests is 5,000, so 5,000/10,000 requests are served immedietly. Then the remaining 5,000 requests are throttled within the one-second period.
